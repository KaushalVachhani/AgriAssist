{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b92ca350",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "import io\n",
    "from PIL import Image\n",
    "from gtts import gTTS\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1019aa48",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.getenv(\"GOOGLE_API_KEY\") is None:\n",
    "    raise ValueError(\"Please set the GOOGLE_API_KEY environment variable.\")\n",
    "else:\n",
    "    genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52c2d9a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I help you today?'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = genai.GenerativeModel('gemini-2.5-flash')\n",
    "model.generate_content(\"Hello\").text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f407f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_multimodal_query(text_input, image_input, audio_input=None):\n",
    "    \"\"\"\n",
    "    Handles farming-related queries by processing a combination of text,\n",
    "    image, and audio input using a Generative AI model.\n",
    "\n",
    "    Args:\n",
    "        text_input (str): The text description of the problem.\n",
    "        image_input (PIL.Image.Image): A PIL Image object of the crop or pest.\n",
    "        audio_input (str): The file path to a recorded audio file.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the AI's text response and the path to\n",
    "               the generated audio file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # --- Handle Audio Input (Placeholder for Transcription) ---\n",
    "        # NOTE: A real-world application would use a speech-to-text model here\n",
    "        # to transcribe the audio into text. For this demo, we'll simply\n",
    "        # acknowledge the audio file and process the other inputs.\n",
    "        if audio_input:\n",
    "            print(f\"Audio file received at: {audio_input}\")\n",
    "            print(\"Placeholder: A speech-to-text model would transcribe this audio.\")\n",
    "            # For a real implementation, you would do something like:\n",
    "            # transcribed_text = transcribe_audio(audio_input)\n",
    "            # text_input = f\"{text_input}\\nTranscribed audio: {transcribed_text}\"\n",
    "\n",
    "        # --- Construct the Multimodal Prompt ---\n",
    "        prompt_parts = [\n",
    "            \"You are an AI assistant specialized in providing advice to farmers. \"\n",
    "            \"Analyze the following information to answer the farmer's question. \"\n",
    "            \"Be practical and concise. If you cannot provide a specific answer, \"\n",
    "            \"provide general helpful advice.\",\n",
    "            f\"\\n\\nFarmer's Question: {text_input}\"\n",
    "        ]\n",
    "\n",
    "        if image_input:\n",
    "            # If an image is provided, add it to the prompt parts for the model\n",
    "            # to analyze alongside the text.\n",
    "            prompt_parts.append(image_input)\n",
    "\n",
    "        # --- Call the Generative AI Model ---\n",
    "        print(\"Sending request to Gemini model...\")\n",
    "        response = model.generate_content(prompt_parts)\n",
    "        ai_text_response = response.text\n",
    "\n",
    "        # --- Step 3: Generate Audio Output from the AI's Response ---\n",
    "        print(\"Generating audio response...\")\n",
    "        tts = gTTS(text=ai_text_response, lang='en')\n",
    "        \n",
    "        # Use a temporary file to store the audio, which Gradio can then use.\n",
    "        with tempfile.NamedTemporaryFile(suffix=\".mp3\", delete=False) as fp:\n",
    "            tts.save(fp.name)\n",
    "            audio_output_path = fp.name\n",
    "\n",
    "        print(\"Audio file generated successfully.\")\n",
    "        return ai_text_response, audio_output_path\n",
    "\n",
    "    except Exception as e:\n",
    "        error_message = f\"An error occurred: {e}\"\n",
    "        print(error_message)\n",
    "        # Clean up the temporary file on error.\n",
    "        if 'audio_output_path' in locals() and os.path.exists(audio_output_path):\n",
    "            os.remove(audio_output_path)\n",
    "        return error_message, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bda5565b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaushalvachhani/Github-Repos/AgriAssist/.venv/lib/python3.12/site-packages/gradio/interface.py:414: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated. Use `flagging_mode` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending request to Gemini model...\n",
      "Generating audio response...\n",
      "Audio file generated successfully.\n",
      "Created dataset file at: .gradio/flagged/dataset1.csv\n"
     ]
    }
   ],
   "source": [
    "# --- Step 4: Build the Gradio Interface ---\n",
    "# Define the input components for the UI.\n",
    "text_box = gr.Textbox(\n",
    "    label=\"Describe your farming issue:\", \n",
    "    placeholder=\"e.g., 'My tomato plant leaves are turning yellow.'\", \n",
    "    interactive=True\n",
    ")\n",
    "image_box = gr.Image(\n",
    "    type=\"pil\", \n",
    "    label=\"Upload an image of the plant (optional):\", \n",
    "    interactive=True\n",
    ")\n",
    "audio_box = gr.Audio(\n",
    "    label=\"Record your question (optional):\", \n",
    "    sources=[\"microphone\"], \n",
    "    interactive=True\n",
    ")\n",
    "\n",
    "# Define the output components for the UI.\n",
    "text_output = gr.Textbox(\n",
    "    label=\"AI Response (Text):\", \n",
    "    placeholder=\"The AI's response will appear here...\", \n",
    "    interactive=False\n",
    ")\n",
    "audio_output = gr.Audio(\n",
    "    label=\"AI Response (Audio):\", \n",
    "    interactive=False\n",
    ")\n",
    "\n",
    "# Create the Gradio interface.\n",
    "gr.Interface(\n",
    "    fn=handle_multimodal_query,\n",
    "    inputs=[text_box, image_box, audio_box],\n",
    "    outputs=[text_output, audio_output],\n",
    "    title=\"Farm AI Assistant Demo\",\n",
    "    description=\"Ask a farming question and get a text and audio response. \"\n",
    "                \"You can use text, an image, or both.\",\n",
    "    allow_flagging=\"auto\",\n",
    ").launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4533e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agriassist",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
